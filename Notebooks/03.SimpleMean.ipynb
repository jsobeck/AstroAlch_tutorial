{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Estimating a Simple Mean\n",
    "\n",
    "In this notebook we will set up the *simplest possible inference problem* and solve it with the same algorithm, but while storing the data in two different places: RAM, and a database.\n",
    "\n",
    "Suppose we have a catalog of stars, each one with an ID and a measured distance. We will assume that they belong to a single population lying at the same distance, and that they are standard candles (so that we have noisy estimates of the distance to each star). Our model has only one parameter, the mean distance to the population.\n",
    "\n",
    "Goals:\n",
    "\n",
    "* Simulate a single stellar population, and generate an observed distance dataset\n",
    "* Load the data in to memory and estimate the mean distance \n",
    "* Create a simple database and store the data in it\n",
    "* Load the data from the database and estimate the mean distance in a few different ways, and compare the time taken and the memorry used. \n",
    "\n",
    "### Requirements\n",
    "\n",
    "You will need to install `sqlalchemy`, and we'll be using `pandas` as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sqlalchemy as sq\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Theory\n",
    "\n",
    "We have measured distances $d_k$ for each star $k$. We are looking for the posterior PDF for the mean distance $\\mu$:\n",
    "\n",
    "${\\rm Pr}(\\mu | \\boldsymbol{d}) = {\\rm Pr}(\\mu) \\prod_k {\\rm Pr}(d_k | \\mu)$\n",
    "\n",
    "We will assign a uniform prior for $\\mu$ and etc etc etc. We're just going to take the arithmetic mean of $d$ and call it $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a Stellar Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StellarPopulation(object):\n",
    "    \"\"\"\n",
    "    Simulate a population of stars, all with the same distance.\n",
    "    \"\"\"\n",
    "    def __init__(self, distance):\n",
    "        \"\"\"\n",
    "        Instantiate a StellarPopulation object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        distance : float\n",
    "            Scalar distance to the cluster of stars, in kpc\n",
    "        \"\"\"\n",
    "        self.distance = distance \n",
    "        return\n",
    "    \n",
    "    def generate(self, N=1000,rms_error=0.1):\n",
    "        \"\"\"\n",
    "        Simulates the observations of N stars.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int\n",
    "            Number of stars to generate\n",
    "        rms_error : float\n",
    "            RMS fractional distance uncertainty\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.rms_error = rms_error\n",
    "        self.d_obs = self.distance + (self.rms_error * self.distance) * np.random.randn(self.N)\n",
    "        self.id = map(str, range(self.N))\n",
    "        return\n",
    "    \n",
    "    def estimate_mean_distance(self):\n",
    "        \"\"\"\n",
    "        Estimate the mean of the observed stellar distances, and return this as well as the wallclock time taken.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mu : float\n",
    "            Estimated mean distance in kpc\n",
    "        time : float\n",
    "            Wallclock time in milliseconds\n",
    "        \"\"\"\n",
    "        import time as wallclock\n",
    "        start = wallclock.time()\n",
    "        mu = np.mean(self.d_obs)\n",
    "        end = wallclock.time()\n",
    "        time = (end-start) * 1e3\n",
    "        return mu, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_stars_per_cluster = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster = StellarPopulation(3.0)\n",
    "cluster.generate(N_stars_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  3.00081275195\n",
      "Wallclock time spent =  0.2 milliseconds\n"
     ]
    }
   ],
   "source": [
    "mu, time = cluster.estimate_mean_distance()\n",
    "print \"Estimated mean distance = \", mu\n",
    "print \"Wallclock time spent = \", np.round(time,1), \"milliseconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setting Up A Database\n",
    "\n",
    "Let's make two tables, one to store information about stellar populations, and one to store measurements of stars within populations. When these two classes are declared, table metadata is prepared and stored in the `Base` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Population(Base):\n",
    "    __tablename__ = 'population'\n",
    "    \n",
    "    id = sq.Column(sq.Integer, primary_key=True)\n",
    "    distance = sq.Column(sq.Float, nullable=False)\n",
    "    \n",
    "class Star(Base):\n",
    "    __tablename__ = 'star'\n",
    "    \n",
    "    id = sq.Column(sq.Integer, primary_key=True)\n",
    "    population_id = sq.Column(sq.Integer, sq.ForeignKey('population.id'), nullable=False)\n",
    "    distance = sq.Column(sq.Float, nullable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbfile = 'mean.db'\n",
    "\n",
    "try: os.remove(dbfile)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = sq.create_engine('sqlite:///'+dbfile)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Base.metadata.bind = engine\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting Data\n",
    "\n",
    "Let's make 10 clusters, each with `N_stars_per_cluster` members, but lying at different mean distances `d_c`. The `population` table will then have 10 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for k in range(10):\n",
    "    d_c = float(k)\n",
    "    clusters.append(StellarPopulation(d_c))\n",
    "    clusters[k].generate(N_stars_per_cluster)    \n",
    "    session.add(Population(id=k, distance=d_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `star` table will contain all the distance measurements `d_s` we have, one for each star. If `N_stars_per_cluster = 100000` then this table will contain 1 million rows. Adding them one by one will take a minute or so. The star `id` must be unique, so we increment it by hand. We could just allow the id's to be created automatically, but then they would be 1-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 s, sys: 1.63 s, total: 55.5 s\n",
      "Wall time: 56.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "j = 0\n",
    "for k in range(10):\n",
    "    for d_s in clusters[k].d_obs:\n",
    "        session.add(Star(id=j, population_id=k, distance=d_s))\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we carry out the transaction, writing all the added records to the database file. This will also take a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 2.71 s, total: 1min 10s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17M\tmean.db\r\n"
     ]
    }
   ],
   "source": [
    "!du -h $dbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Data and Estimating the Mean\n",
    "\n",
    "Let's do this two different ways. First, we'll query for the all the distances to stars in population 3, unpack them and calculate the mean. We'll see that it makes a difference whether we ask for all the stars and then compute their mean distance, if we ask for all stellar distances and then compute their mean. Then, we'll use the inbuilt `SQLite` `avg` function to compute the mean distance from within the database, for comparison. The session, and the classes defining the tables and their entries, are all global objects, accessible to the short function we will use for estimating the mean stellar distance. \n",
    "\n",
    "In this function we use the `time` package to measure wallclock time, and `guppy` to measure memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_mean(k=3,method='sql_function'):\n",
    "    \n",
    "    import time as wallclock\n",
    "    import guppy\n",
    "    \n",
    "    measure = guppy.hpy()\n",
    "    \n",
    "    start, end = {}, {}\n",
    "    start['memory'] = measure.heap().size\n",
    "    start['time'] = wallclock.time()\n",
    "    \n",
    "    stars, distances, mean = None, None, None\n",
    "\n",
    "    if method == 'query_stars':\n",
    "        stars = session.query(Star).filter(Star.population_id == k).all()\n",
    "        mean = np.mean(np.array([s.distance for s in stars]))\n",
    "\n",
    "    elif method == 'query_distances':\n",
    "        distances = session.query(Star.distance).filter(Star.population_id == k).all()\n",
    "        mean = np.mean(np.array([d.distance for d in distances]))\n",
    "  \n",
    "    elif method == 'pandas_query_stars':\n",
    "        df = pd.read_sql(session.query(Star).filter(Star.population_id == k).statement, session.bind) \n",
    "        mean = np.mean(df.distance)\n",
    "        \n",
    "    elif method == 'pandas_query_distances':\n",
    "        df = pd.read_sql(session.query(Star.distance).filter(Star.population_id == k).statement, session.bind) \n",
    "        mean = np.mean(df.distance)\n",
    "        \n",
    "    elif method == 'sql_function':\n",
    "        mean = session.query(func.avg(Star.distance)).filter(Star.population_id == k).one()[0]\n",
    "        \n",
    "    \n",
    "    end['time'] = wallclock.time()\n",
    "    end['memory'] = measure.heap().size\n",
    "\n",
    "    time = (end['time']-start['time']) * 1e3\n",
    "    memory = (end['memory']-start['memory']) / (1024.0*1024.0)\n",
    "\n",
    "    print \"Estimated mean distance = \", mean\n",
    "\n",
    "    print \"Wallclock time spent = \", np.round(time,1), \"milliseconds\"\n",
    "    print \"Memory used = \",np.round(memory,1), \"Mb\"\n",
    "    \n",
    "    del stars, distances, mean\n",
    "\n",
    "    return time, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  2.99972073362\n",
      "Wallclock time spent =  2982.2 milliseconds\n",
      "Memory used =  222.1 Mb\n"
     ]
    }
   ],
   "source": [
    "t, m = estimate_mean(method='query_stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's faster to query for just the distance, not the whole star:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  2.99972073362\n",
      "Wallclock time spent =  548.3 milliseconds\n",
      "Memory used =  9.3 Mb\n"
     ]
    }
   ],
   "source": [
    "t, m = estimate_mean(method='query_distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we read the stars, or distances, into a `pandas` data frame, and used that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  2.99972073362\n",
      "Wallclock time spent =  571.7 milliseconds\n",
      "Memory used =  0.1 Mb\n"
     ]
    }
   ],
   "source": [
    "t, m = estimate_mean(method='pandas_query_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  2.99972073362\n",
      "Wallclock time spent =  487.1 milliseconds\n",
      "Memory used =  0.1 Mb\n"
     ]
    }
   ],
   "source": [
    "t, m = estimate_mean(method='pandas_query_distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though `pandas` is doing something clever with the memory, and speeding up the array extraction as well.\n",
    "\n",
    "How does this compare with doing the math in SQL directly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mean distance =  2.99972073362\n",
      "Wallclock time spent =  159.8 milliseconds\n",
      "Memory used =  0.1 Mb\n"
     ]
    }
   ],
   "source": [
    "t, m = estimate_mean(method='sql_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The slowest thing you can do is loop over the rows in a table, pulling out each row as its own object. In our test case it was a factor of ~5 faster to just extract the distances. `pandas` allows you to avoid this difference: it was only 25% slower to read the whole table into a `pandas` data frame and compute a mean as it was to extract and work on just the column we wanted. Single column extraction and averaging was about 50% faster with `pandas`.\n",
    "\n",
    "Calculating an average was about 3 times faster using the built-in SQL `avg` function than doing a `np.mean()` on an extracted column (whether or not it is read into a `pandas` dataframe). This procedure also used 2000 times less memory than reading all the objects into memory, and 100 times less than just reading in the column we needed. Using `pandas` seemed to be as memory-efficient as doing the calculation in the database, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: os.remove(dbfile)\n",
    "except: pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
